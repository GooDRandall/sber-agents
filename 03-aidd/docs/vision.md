# Техническое видение LLM‑ассистента (Telegram‑бот)

## Технологии (согласовано)
- Python: 3.12
- Управление зависимостями: uv
- Интеграция с Telegram: aiogram 3.x, метод polling
- Работа с LLM: официальный `openai` Python client через провайдера OpenRouter (`base_url` на OpenRouter)
- Модель по умолчанию: `openrouter/auto` (может быть переопределена конфигурацией)
- Формат ответа: без стриминга — единое сообщение после генерации
- Конфигурация: `.env` + простой модуль `config.py`
- Логгирование: стандартный модуль `logging`, уровни INFO/ERROR, вывод в stdout
- Контекст диалога: локально в файловой системе (текстовые файлы) по `chat_id`, без БД
- Сборка/запуск: `make` цели `install`, `run`, `clean`

## Принцип разработки
- KISS/YAGNI: реализуем только необходимое для MVP.
- Разработка локально: без ветвления и версионирования; финальную версию загрузим в Git в конце.
- Качество кода: пишем максимально читаемо; авто-форматтеры/линтеры можно добавить позже при необходимости.
- Тестирование: ручная проверка основных сценариев.
- Запуск/сборка: локально через `make run`; дополнительные цели по мере надобности.
- Обработка ошибок: логирование и безопасные фолыбэки без падения процесса.
- Документация: поддерживаем в актуальном состоянии `docs/vision.md` и краткий `README.md`.

## Структура проекта
- `docs/` — документация (`idea.md`, `vision.md`)
- `src/`
  - `bot/`
    - `main.py` — входная точка бота (aiogram, polling)
    - `handlers.py` — обработчики сообщений
  - `llm/`
    - `client.py` — обёртка над OpenRouter через `openai` client
    - `prompt.py` — системный промпт и функции сборки сообщений
    - `summarizer.py` — функции суммаризации истории
  - `config.py` — загрузка переменных окружения
  - `context.py` — интерфейс управления историей (использует `storage.py`)
  - `storage.py` — файловое хранилище истории и суммаризаций
  - `logging_setup.py` — базовая настройка `logging`
- `data/` — директория для локальных файлов историй и суммаризаций (в `.gitignore`)
- `.env.example` — список переменных окружения
- `Makefile` — цели `install`, `run`, `clean`
- `README.md` — краткая инструкция по запуску

## Архитектура проекта
- Слои:
  - `bot`: получение апдейтов (polling), роутинг, обработчики сообщений.
  - `llm`: тонкая обёртка вызова OpenRouter через `openai` client.
  - `infra`: конфиг (`config.py`), логгирование (`logging_setup.py`), контекст и файловое хранилище (`context.py`/`storage.py`).
- Поток обработки запроса:
  1) `aiogram` получает сообщение → `bot/handlers.py`.
  2) Читаем последние сообщения окна (20) и актуальную суммаризацию из `context.py`/`storage.py` по `chat_id`.
  3) Собираем системный и пользовательский промпт плюс краткую суммаризацию (`llm/prompt.py`).
  4) Вызываем LLM (`llm/client.py`) и получаем полный ответ (без стриминга).
  5) Обновляем историю диалога в `context.py`/`storage.py`.
  6) Если сумма сообщений в чате достигла кратности 20 — выполняем суммаризацию блока (`llm/summarizer.py`), сохраняем/сливаем суммаризации.
  7) Отправляем ответ одним сообщением пользователю.
- Ошибки: логируем и возвращаем короткое сервисное сообщение при сбое.

## Модель данных
- Окно истории: 20 последних сообщений.
- Суммаризация: создаётся после каждых 20 сообщений; при следующей суммаризации происходит слияние (предыдущей суммаризации и нового блока) в краткую сводку.
- Сущности (логические):
  - `Message`: `role` (`system`/`user`/`assistant`), `content`, `timestamp`.
  - `ChatSession`: `chat_id`, `messages_count`, текущая «сводка» (summary), опционально история суммаризаций.
- Хранение (файлы, UTF-8):
  - `data/<chat_id>/messages.txt` — текстовый лог сообщений в порядке поступления (по одному на строке с метаданными).
  - `data/<chat_id>/summary.txt` — последняя слитая суммаризация, которая добавляется в промпт как контекст.
  - (опционально) `data/<chat_id>/summaries.log` — история суммаризаций (для отладки).
  - `data/<chat_id>/meta.json` — счётчики и служебные поля (например, `messages_count`).

## Работа с LLM
- Генерация ответа: системный промпт + (summary, если есть) + последние 20 сообщений + новое входящее сообщение.
- Суммаризация: отдельный вызов модели с инструкцией «сжать последние 20 сообщений + пред. сводку в краткую сводку»; результат сохраняется в `summary.txt`.
- Модель: `openrouter/auto` по умолчанию, может быть переопределена в конфиге.
- Таймауты/ретраи: минимально — один повтор при сетевой ошибке (опционально включаемо).
 - Язык суммаризации: русский. Формат — короткий абзац 5–8 строк, без списков.

## Сценарии работы
- Пользователь пишет сообщение → бот отвечает единым сообщением.
- Каждые 20 сообщений по чату: выполняется суммаризация блока и слияние с текущей сводкой.
- Команда `/reset`: очистка истории и суммаризации для текущего чата.
- При перезапуске бота контекст восстанавливается из файлов.
- При ошибках LLM/сети: бот отвечает коротким сервисным сообщением и логирует ошибку.

## Подход к конфигурированию
- Переменные окружения (.env):
  - `TELEGRAM_BOT_TOKEN`
  - `OPENROUTER_API_KEY`
  - `OPENROUTER_BASE_URL` (по умолчанию адрес OpenRouter)
  - `OPENROUTER_MODEL` (по умолчанию `openrouter/auto`)
  - `DATA_DIR` (по умолчанию `data/`)
  - `WINDOW_SIZE` (по умолчанию `20`)
  - `ENABLE_RETRY` (по умолчанию `false`)

## Подход к логгированию
- Уровни: INFO/ERROR, вывод в stdout, уровень из `LOG_LEVEL` (дефолт `INFO`).
- Формат: `%(asctime)s %(levelname)s %(name)s: %(message)s` (UTC необязательно).
- Логируем: метаданные запросов к LLM (модель, длительность, статус), ошибки, факты суммаризаций (создание/слияние), пути файлов.
- Не логируем: содержимое пользовательских сообщений и полный ответ модели (только при отладке по необходимости).
- Шум aiogram: по умолчанию оставляем на уровне INFO; при избыточности можно поднять до WARNING.
- Ротация логов не требуется (stdout); для отладки суммаризаций возможно вести `data/<chat_id>/summaries.log`.


