# Отчёт о выполнении задания

## Название проекта и краткое описание

**Персональный финансовый советник** — Telegram-бот для учета доходов и расходов с интеграцией LLM через Ollama. Бот умеет извлекать транзакции из текстовых сообщений, обрабатывать изображения чеков и транскрибировать голосовые сообщения через Whisper.

## Вариант задания

**Расширенный вариант** — реализована полная функциональность:
- Обработка текстовых сообщений
- Обработка изображений (чеки, скриншоты)
- Транскрибация голосовых сообщений через Whisper
- Автоматическая категоризация транзакций
- Отчеты о балансе и статистике

## Реализованные возможности

- [x] Извлечение транзакций из текстовых сообщений через LLM
- [x] Обработка изображений чеков и скриншотов через Vision-модель
- [x] Транскрибация голосовых сообщений через Whisper на удаленном сервере
- [x] Автоматическая категоризация транзакций (продукты, рестораны, такси и т.д.)
- [x] Команда `/start` — начало нового диалога (сброс истории и транзакций)
- [x] Команда `/balance` — отчет о балансе, доходах, расходах и статистике по категориям
- [x] Команда `/transactions` — список всех транзакций
- [x] Хранение истории диалогов для контекста
- [x] Structured output через Pydantic для валидации ответов LLM
- [x] Поддержка локальных моделей через Ollama
- [x] SSH-подключение к удаленному серверу для транскрибации
- [x] Обработка ошибок с понятными сообщениями пользователю

## Технологический стек

### Основные технологии
- **Python 3.11+** — основной язык разработки
- **uv** — менеджер зависимостей и виртуальных окружений
- **aiogram 3.15.0+** — фреймворк для Telegram Bot API (асинхронный polling)
- **openai 1.54.0+** — клиент для работы с LLM через единый интерфейс (OpenRouter/Ollama)
- **pydantic 2.0.0+** — валидация данных и structured output для LLM
- **python-dotenv 1.0.0+** — работа с переменными окружения
- **paramiko 3.0.0+** — SSH-подключение к удаленному серверу

### Используемые модели

**LLM модели (Ollama на удаленном сервере):**
- `qwen2.5:7b-instruct` — для обработки текстовых сообщений
- `qwen3-vl:8b-instruct` — для обработки изображений (vision)

**Модель транскрибации:**
- `openai-whisper` (модель `base`) — для транскрибации голосовых сообщений

### Инфраструктура
- **Make** — автоматизация сборки и запуска
- **SSH** — подключение к удаленному серверу для транскрибации
- **ffmpeg** — обработка аудиофайлов (установлен на удаленном сервере)

## Инструменты AI-driven разработки

### IDE
- **Cursor** — AI-powered IDE с интеграцией LLM для автодополнения и рефакторинга

### LLM модели для разработки
- **Claude Sonnet 4.5** (через Cursor) — основной инструмент для написания кода, рефакторинга и отладки
- Использовались для:
  - Генерации кода обработчиков
  - Реализации транскрибации через SSH
  - Отладки и исправления ошибок
  - Оптимизации кода
  - Написания документации

## Скриншоты работы

![Работа бота](screenshots/bot.png)

## Облачный сервер

**Провайдер:** [immers.cloud](https://immers.cloud/vm/) — облачная платформа с GPU-серверами

**Конфигурация сервера:**
- **GPU:** Tesla V100
- **IP адрес:** 195.209.210.129
- **ОС:** Ubuntu 24.04
- **Пользователь:** ubuntu

**Установленные сервисы:**
- **Ollama** — запущен на порту 11434, модели:
  - `qwen2.5:7b-instruct` (текстовая модель)
  - `qwen3-vl:8b-instruct` (vision модель)
- **Whisper** — установлен в виртуальном окружении `~/whisper-env` с моделью `base`
- **ffmpeg** — установлен для обработки аудиофайлов

**Подключение:**
- SSH через ключ `.ssh/immers-vm.pem`
- Транскрибация выполняется на удаленном сервере через SSH/SFTP

## Проблемы и их решения

### Проблема с faster-whisper

**Проблема:** Изначально планировалось использовать `faster-whisper` из Hugging Face для более быстрой транскрибации, но модель не загружалась с Hugging Face Hub из-за проблем с сетью или доступностью репозитория.

**Решение:** Перешли на использование `openai-whisper` — оригинальную библиотеку от OpenAI. Хотя она немного медленнее на CPU, но:
- Стабильно работает
- Легко устанавливается через pip
- Хорошо документирована
- Модель `base` обеспечивает хороший баланс скорости и точности

**Результат:** Транскрибация работает стабильно, время обработки приемлемое (7-10 секунд для коротких сообщений).

### Другие проблемы

1. **Проблема с путем к SSH ключу** — ключ находился в корне репозитория, а код искал его в `live/`. Решено добавлением логики поиска ключа в нескольких местах.

2. **Отсутствие ffmpeg на сервере** — Whisper требует ffmpeg для обработки аудио. Решено установкой через `apt-get install ffmpeg`.

3. **Неправильная модель LLM** — в конфигурации была указана несуществующая модель `gpt-oss:20b`. Исправлено на `qwen2.5:7b-instruct`, которая доступна на Ollama сервере.

## Что узнал нового

1. **Работа с Ollama через OpenAI-совместимый API** — узнал, что Ollama предоставляет OpenAI-совместимый интерфейс, что позволяет использовать стандартный `openai` клиент для работы с локальными моделями. Это упрощает переключение между облачными и локальными провайдерами.

2. **SSH-подключение и удаленная транскрибация** — реализовал систему транскрибации через SSH, где аудиофайл загружается на удаленный сервер, обрабатывается там через Whisper, и результат возвращается обратно. Это позволило использовать мощный GPU-сервер для транскрибации без необходимости устанавливать Whisper локально.

3. **Работа с Vision-моделями** — изучил, как передавать изображения в LLM через base64-кодирование и как использовать vision-модели (qwen3-vl) для извлечения информации из чеков и скриншотов.

## Заключение

Проект успешно реализован с использованием современных технологий и AI-driven подхода к разработке. Бот полностью функционален и готов к использованию. Все основные возможности реализованы, включая обработку текста, изображений и голосовых сообщений.

