Реализуй транскрибацию голосовых сообщений Telegram для финансового бота на Python.

КОНТЕКСТ ПРОЕКТА:
- Telegram-бот на Python 3.11+ с aiogram 3.x
- Использует LLM (OpenRouter/Ollama) для извлечения транзакций из текста и изображений
- Хранит транзакции в памяти: transactions: dict[int, list[Transaction]]
- Хранит историю: chat_conversations: dict[int, list[dict]]
- Существующие обработчики: текстовые сообщения и изображения

СТРУКТУРА:
live/src/
  - bot.py (точка входа)
  - handlers.py (обработчики сообщений)
  - llm.py (get_transaction_response_text, get_transaction_response_image)
  - models.py (Transaction, TransactionResponse)
  - config.py (Config класс с переменными окружения)

ЗАДАЧА:
Добавить транскрибацию голосовых сообщений через локальный Whisper. Whisper хостится на том же сервере, где работает Ollama (модель для изображений). После транскрибации текст обрабатывается как обычное текстовое сообщение.

ТРЕБОВАНИЯ:

1. pyproject.toml - добавить зависимость:
   "openai-whisper>=20231117"

2. src/config.py - добавить в класс Config:
   WHISPER_MODEL = os.getenv("WHISPER_MODEL", "base")  # tiny, base, small, medium, large

3. src/transcription.py - создать новый файл:
   - Функция transcribe_audio(audio_path: str | Path) -> str
   - Использовать openai-whisper
   - Кэшировать модель в глобальной переменной (ленивая загрузка)
   - Использовать config.WHISPER_MODEL для выбора модели
   - Логировать загрузку модели и транскрибацию
   - Обрабатывать ошибки

4. src/handlers.py - добавить обработчик голосовых сообщений:
   @router.message(lambda message: message.voice)
   async def handle_voice(message: Message):
       # 1. Получить file_info через message.bot.get_file(message.voice.file_id)
       # 2. Скачать файл во временный файл (tempfile) или BytesIO
       # 3. Транскрибировать через transcription.transcribe_audio()
       # 4. Инициализировать chat_conversations[chat_id] если нет
       # 5. Обработать транскрибированный текст через get_transaction_response_text()
       # 6. Сохранить транзакции в transactions[chat_id]
       # 7. Рассчитать баланс
       # 8. Сформировать ответ: транскрипция + ответ LLM + статус + баланс
       # 9. Добавить в историю диалога
       # 10. Отправить ответ пользователю
       # Обработать исключения с логированием

5. .env.example - добавить:
   # Whisper модели: tiny (быстрая), base (баланс), small, medium, large (точная, медленная)
   WHISPER_MODEL=base

ТЕХНИЧЕСКИЕ ДЕТАЛИ:
- Whisper хостится локально на том же сервере, где работает Ollama (модель для изображений)
- Telegram голосовые сообщения в формате OGG Opus
- Whisper может работать напрямую или через конвертацию (pydub/ffmpeg)
- Модели автоматически загружаются в ~/.cache/whisper/
- На CPU: ~10-30 сек для 1 мин аудио, на GPU: ~1-3 сек
- Рекомендуется модель "base" или "small"
- Установка и настройка аналогичны Ollama - локально на сервере

ПРИНЦИПЫ:
- KISS - максимальная простота
- Асинхронная обработка
- Логирование всех этапов
- Обработка ошибок

Начни с создания transcription.py, затем обнови остальные файлы.

